{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7lKiy7jARck-"
   },
   "outputs": [],
   "source": [
    "# Loading all important Libraries\n",
    "import numpy as np\n",
    "import pickle\n",
    "from keras.models import model_from_json\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import re\n",
    "from prettytable import PrettyTable\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Lj5wza4MRxeR"
   },
   "outputs": [],
   "source": [
    "class final:\n",
    "    def load_files(self): # This function loads all important files\n",
    "        #https://machinelearningmastery.com/save-load-keras-deep-learning-models/\n",
    "        json_file = open('model.json', 'r') #Loads model\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        self.model = model_from_json(loaded_model_json)\n",
    "        self.model.load_weights(\"model.h5\") # Loads weights of model\n",
    "\n",
    "        with open('access_enc.pkl','rb') as file:\n",
    "            self.access_enc=pickle.load(file) #Loads label encoder for access\n",
    "\n",
    "        with open('lang_enc.pkl','rb') as file:\n",
    "            self.lang_enc=pickle.load(file) #Loads label encoder for language\n",
    "\n",
    "        with open('spider_enc.pkl','rb') as file:\n",
    "            self.agent_enc=pickle.load(file) #Loads label encoder for agent\n",
    "        self.new_data=pd.read_csv('final_data.csv')    #Loads data which is required to make prediction \n",
    "    \n",
    "    def find_access(self,page):#This function finds the client of the page for which we are making prediction\n",
    "        k=max([i.start() for i in re.finditer('org_',page)])   #https://www.geeksforgeeks.org/python-all-occurrences-of-substring-in-string/\n",
    "        if('all-access' in page[k:]):\n",
    "            access='all_access'\n",
    "        if('desktop' in page[k:]):\n",
    "            access='desktop'\n",
    "        if('mobile' in page[k:]): \n",
    "            access='mobile'\n",
    "        k=access    \n",
    "        access=self.access_enc.transform([access]).reshape(1,1)    \n",
    "        return access,k \n",
    "    \n",
    "    def find_lang(self,page): # This function finds language of the page for which we are making prediction\n",
    "        index=page.find('.wikipedia')\n",
    "        lang=page[index-1:index-3:-1][::-1]\n",
    "        lang_dict={'de':'German','en':'English', 'es':'Spanish', 'fr':'French', 'ja':'Japanese', 'nt':'Media', 'ru':'Russian', 'zh':'Chinese'}\n",
    "        language=lang_dict[lang]\n",
    "        lang=self.lang_enc.transform([lang]).reshape(1,1)\n",
    "        return lang,language\n",
    "    \n",
    "    \n",
    "    def find_agent(self,page): #This page finds if the page was accessed by a spider or not.\n",
    "        if('spider' in page):\n",
    "            spider='spider'\n",
    "        else:\n",
    "            spider='non-spider' \n",
    "        k=spider  \n",
    "        agent=self.agent_enc.transform([spider]).reshape(1,1)\n",
    "        return agent,k\n",
    "    \n",
    "    \n",
    "    def find_data(self,ind,date): \n",
    "        ''' This function returns the traffic on last 5 days on the page on which we are making prediction,\n",
    "         this data is neccessary in order to make prediction and this data will be fed to loaded model.'''\n",
    "        data=self.new_data.iloc[ind].values\n",
    "        date1=datetime.date(2015,7,6)\n",
    "        k=date.split('-')\n",
    "        date2=datetime.date(int(k[0]),int(k[1]),int(k[2]))\n",
    "        dif=(date2-date1).days\n",
    "        data=np.log1p(data[dif+1:dif+6].astype(int))\n",
    "        data=np.array(data).reshape(1,5,1)\n",
    "        return data    \n",
    "    \n",
    "    \n",
    "    def final_fun_1(self,ind,date): # This data takes index of the page and date as input for which we want to make prediction\n",
    "        self.load_files()\n",
    "        start=datetime.datetime.now()\n",
    "        self.page=self.new_data['Page'].values[ind]\n",
    "        access,access1=self.find_access(self.page)\n",
    "        lang,language=self.find_lang(self.page)\n",
    "        agent,agent1=self.find_agent(self.page)\n",
    "        data=self.find_data(ind,date)\n",
    "        predicted=int(np.round(np.expm1(self.model.predict([data,access,lang,agent])[0])[0]))\n",
    "        \n",
    "        x = PrettyTable()\n",
    "        x = PrettyTable([\"Client\",\"Access\", \"Language\",'Predicted','Time Taken'])\n",
    "        x.add_row([agent1,access1,language,predicted,datetime.datetime.now()-start])\n",
    "\n",
    "        print(x)\n",
    "        #Prints the client,access,language,time taken and predicted traffic on the page\n",
    "        \n",
    "        \n",
    "    def final_fun_2(self,set): #This function takes index,date and actual traffic on the page as input, can also take a list of multiple inputs\n",
    "        self.load_files()\n",
    "        x = PrettyTable()\n",
    "        x = PrettyTable([\"Client\",\"Access\", \"Language\",'Predicted','Actual','SMAPE','Time Taken'])\n",
    "        for val in set:\n",
    "            start=datetime.datetime.now()\n",
    "            self.page=self.new_data['Page'].values[val[0]]\n",
    "            access,access1=self.find_access(self.page)\n",
    "            lang,language=self.find_lang(self.page)\n",
    "            agent,agent1=self.find_agent(self.page)\n",
    "            data=self.find_data(val[0],val[1])\n",
    "            actual=int(val[2])\n",
    "            predicted=int(np.round(np.expm1(self.model.predict([data,access,lang,agent],steps=1)[0])[0]))\n",
    "            smape=np.abs(actual-predicted)/((actual+predicted)/2)\n",
    "\n",
    "            x.add_row([agent1,access1,language,predicted,actual,np.round(smape,3),datetime.datetime.now()-start])\n",
    "            #Print client,access,language,prediction,actual,time taken and SMAPE of the page\n",
    "        print(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZ7pxLADbtRz"
   },
   "source": [
    "In the above final functions taken 10K pages to optimize the time and preprocessed them to test the model, it will work same on the whole data as well. Loaded the saved lstm model to predict and label encoded language, access and agent feature and used to transformed the test data feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Jh7bKkJvT3CI"
   },
   "outputs": [],
   "source": [
    "final_object = final() #creating the object of final class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uC1K-TEeT1B-"
   },
   "source": [
    "It is not possible to take all the features name or any particular page name so taken a index and date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Df-hykZT67g",
    "outputId": "32b5a111-ba5a-473a-eb15-2a6173ae1ae2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+----------+-----------+----------------+\n",
      "| Client |   Access   | Language | Predicted |   Time Taken   |\n",
      "+--------+------------+----------+-----------+----------------+\n",
      "| spider | all_access | Chinese  |     11    | 0:00:00.323582 |\n",
      "+--------+------------+----------+-----------+----------------+\n"
     ]
    }
   ],
   "source": [
    "final_object.final_fun_1(22,'2016-02-17') #taken a random page index to test the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "2j9ZhP4YUkqe",
    "outputId": "0063e645-d1b1-410d-b4f5-4fd74257f0d1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page</th>\n",
       "      <th>2015-07-01</th>\n",
       "      <th>2015-07-02</th>\n",
       "      <th>2015-07-03</th>\n",
       "      <th>2015-07-04</th>\n",
       "      <th>2015-07-05</th>\n",
       "      <th>2015-07-06</th>\n",
       "      <th>2015-07-07</th>\n",
       "      <th>2015-07-08</th>\n",
       "      <th>2015-07-09</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-09-01</th>\n",
       "      <th>2017-09-02</th>\n",
       "      <th>2017-09-03</th>\n",
       "      <th>2017-09-04</th>\n",
       "      <th>2017-09-05</th>\n",
       "      <th>2017-09-06</th>\n",
       "      <th>2017-09-07</th>\n",
       "      <th>2017-09-08</th>\n",
       "      <th>2017-09-09</th>\n",
       "      <th>2017-09-10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5566_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Intel_80386_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kara_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>56.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAMAMOO_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Netflix_zh.wikipedia.org_all-access_spider</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 804 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Page  2015-07-01  2015-07-02  \\\n",
       "0         5566_zh.wikipedia.org_all-access_spider        12.0         7.0   \n",
       "1  Intel_80386_zh.wikipedia.org_all-access_spider         7.0         5.0   \n",
       "2         Kara_zh.wikipedia.org_all-access_spider        56.0        25.0   \n",
       "3      MAMAMOO_zh.wikipedia.org_all-access_spider         8.0         7.0   \n",
       "4      Netflix_zh.wikipedia.org_all-access_spider         7.0        10.0   \n",
       "\n",
       "   2015-07-03  2015-07-04  2015-07-05  2015-07-06  2015-07-07  2015-07-08  \\\n",
       "0         4.0         5.0        20.0         8.0         5.0        17.0   \n",
       "1         9.0         3.0         5.0         1.0         6.0         6.0   \n",
       "2         7.0        50.0        90.0        30.0        19.0        16.0   \n",
       "3        17.0        11.0         8.0         1.0         1.0        10.0   \n",
       "4        21.0         2.0         9.0        13.0         7.0         6.0   \n",
       "\n",
       "   2015-07-09  ...  2017-09-01  2017-09-02  2017-09-03  2017-09-04  \\\n",
       "0        24.0  ...        13.0        13.0        45.0         4.0   \n",
       "1         3.0  ...         7.0         7.0        10.0         9.0   \n",
       "2        10.0  ...        13.0        13.0        11.0         9.0   \n",
       "3         6.0  ...         9.0        19.0        17.0        19.0   \n",
       "4         7.0  ...        23.0        37.0        38.0        21.0   \n",
       "\n",
       "   2017-09-05  2017-09-06  2017-09-07  2017-09-08  2017-09-09  2017-09-10  \n",
       "0        13.0        20.0        18.0        17.0        14.0        11.0  \n",
       "1         2.0         6.0         7.0         9.0         6.0         5.0  \n",
       "2         9.0        14.0        19.0        36.0        10.0         8.0  \n",
       "3         8.0         4.0        10.0        10.0        10.0        11.0  \n",
       "4        35.0        29.0        35.0        25.0        24.0        22.0  \n",
       "\n",
       "[5 rows x 804 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('final_data.csv') # Reading data in order to provide actual data as input\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QZLgp6CCb28f",
    "outputId": "b708c683-8828-4881-aed0-b2d975294da8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+----------+-----------+--------+-------+----------------+\n",
      "|   Client   |   Access   | Language | Predicted | Actual | SMAPE |   Time Taken   |\n",
      "+------------+------------+----------+-----------+--------+-------+----------------+\n",
      "|   spider   | all_access | Chinese  |     4     |   1    |  1.2  | 0:00:00.367015 |\n",
      "|   spider   | all_access | Chinese  |     2     |   5    | 0.857 | 0:00:00.053291 |\n",
      "| non-spider |   mobile   | Russian  |    145    |   77   | 0.613 | 0:00:00.054133 |\n",
      "| non-spider |  desktop   |  French  |    297    |  163   | 0.583 | 0:00:00.059461 |\n",
      "+------------+------------+----------+-----------+--------+-------+----------------+\n"
     ]
    }
   ],
   "source": [
    "final_object.final_fun_2([(23,'2015-11-13',data.at[23,'2015-11-13']),\n",
    "                         (153,'2016-12-03',data.at[153,'2016-12-03']), #Providing a list of 4 inputs\n",
    "                         (1139,'2017-04-13',data.at[1139,'2017-04-13']),\n",
    "                         (482,'2015-09-17',data.at[482,'2015-09-17'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "final_submission",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
